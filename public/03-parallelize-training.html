<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="generator" content="pandoc">
  <meta name="author" content="Alexandre Strube // Sabrina Benassou">
  <meta name="dcterms.date" content="2023-12-13">
  <title>Getting Started with AI on Supercomputers</title>
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no, minimal-ui">
  <link rel="stylesheet" href="./dist/reset.css">
  <link rel="stylesheet" href="./dist/reveal.css">
  <style>
    .reveal .sourceCode {  /* see #7635 */
      overflow: visible;
    }
    code{white-space: pre-wrap;}
    span.smallcaps{font-variant: small-caps;}
    div.columns{display: flex; gap: min(4vw, 1.5em);}
    div.column{flex: auto; overflow-x: auto;}
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
    ul.task-list{list-style: none;}
    ul.task-list li input[type="checkbox"] {
      width: 0.8em;
      margin: 0 0.8em 0.2em -1.6em;
      vertical-align: middle;
    }
    .display.math{display: block; text-align: center; margin: 0.5rem auto;}
    /* CSS for syntax highlighting */
    pre > code.sourceCode { white-space: pre; position: relative; }
    pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
    pre > code.sourceCode > span:empty { height: 1.2em; }
    .sourceCode { overflow: visible; }
    code.sourceCode > span { color: inherit; text-decoration: inherit; }
    div.sourceCode { margin: 1em 0; }
    pre.sourceCode { margin: 0; }
    @media screen {
    div.sourceCode { overflow: auto; }
    }
    @media print {
    pre > code.sourceCode { white-space: pre-wrap; }
    pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
    }
    pre.numberSource code
      { counter-reset: source-line 0; }
    pre.numberSource code > span
      { position: relative; left: -4em; counter-increment: source-line; }
    pre.numberSource code > span > a:first-child::before
      { content: counter(source-line);
        position: relative; left: -1em; text-align: right; vertical-align: baseline;
        border: none; display: inline-block;
        -webkit-touch-callout: none; -webkit-user-select: none;
        -khtml-user-select: none; -moz-user-select: none;
        -ms-user-select: none; user-select: none;
        padding: 0 4px; width: 4em;
        color: #aaaaaa;
      }
    pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
    div.sourceCode
      {   }
    @media screen {
    pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
    }
    code span.al { color: #ff0000; font-weight: bold; } /* Alert */
    code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
    code span.at { color: #7d9029; } /* Attribute */
    code span.bn { color: #40a070; } /* BaseN */
    code span.bu { color: #008000; } /* BuiltIn */
    code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
    code span.ch { color: #4070a0; } /* Char */
    code span.cn { color: #880000; } /* Constant */
    code span.co { color: #60a0b0; font-style: italic; } /* Comment */
    code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
    code span.do { color: #ba2121; font-style: italic; } /* Documentation */
    code span.dt { color: #902000; } /* DataType */
    code span.dv { color: #40a070; } /* DecVal */
    code span.er { color: #ff0000; font-weight: bold; } /* Error */
    code span.ex { } /* Extension */
    code span.fl { color: #40a070; } /* Float */
    code span.fu { color: #06287e; } /* Function */
    code span.im { color: #008000; font-weight: bold; } /* Import */
    code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
    code span.kw { color: #007020; font-weight: bold; } /* Keyword */
    code span.op { color: #666666; } /* Operator */
    code span.ot { color: #007020; } /* Other */
    code span.pp { color: #bc7a00; } /* Preprocessor */
    code span.sc { color: #4070a0; } /* SpecialChar */
    code span.ss { color: #bb6688; } /* SpecialString */
    code span.st { color: #4070a0; } /* String */
    code span.va { color: #19177c; } /* Variable */
    code span.vs { color: #4070a0; } /* VerbatimString */
    code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
  </style>
  <link rel="stylesheet" href="./dist/theme/sky.css" id="theme">
  <style>
  .container{
    display: flex;
  }
  .col {
    flex: 1;
  }

  .slides {
      font-size: 0.75em;
  }
  .reveal ul {
      display: block;
  }
  .reveal ol {
      display: block;
  }

  img {
      max-height: 600px !important;
  }

  figcaption {
      font-size: 0.6em !important;
      font-style: italic !important;
  }

  .subtitle {
      font-style: italic !important;
  }

  .date {
      font-size: 0.75em !important;
  }


  body {
      font-family: "Arial", "sans-serif"
  }

  section {
      margin: 0;
  }

  .reveal .slides {
      margin: 0 1vmin;
  }
  .reveal h1,
  .reveal h2,
  .reveal h3,
  .reveal h4 {
      font-family: "Arial", "sans-serif";
      text-transform: Uppercase;
      color: #023d6b;
  }

  .reveal h1 {
      color: #023d6b;
      font-size: 250%;
  }


  .reveal h2 + h3 {
      text-transform: Unset;
      font-size: 80%;
  }

  .controls {
      visibility: hidden;
  }

  .reveal .progress {
      position: absolute;
      bottom: 1px;
  }

  .prompt {
      min-width: 0;
      width: 0;
      visibility: hidden;
  }

  div.dateauthor {
      padding-top: 4em;
      color: white;
  }

  div.prompt {
      width:0;
  }


  div#footer {
      position: fixed;
      bottom: 0;
      width: 100%;
      z-index: 10;
  font-size: 0.5em; font-weight: bold; padding: 0 1vmin; height: 20vmin; background: #fff}
  #footer h1 {
      position: absolute; 
      bottom: 3.2vmin; 
      display: block; 
      padding: 0 1em; 
      font-size: 1.7vmin;
      font-weight: bold;
      text-transform: unset;
      color: #023d6b;
  }
  #footer h2 {display: block; padding: 0.em 1em 0;}

  img.fzjlogo {
      position: fixed;
      bottom: 0;
      right: 0;
      height: 24vmin; /* The height of the svg is about 3 times the height of the logo */
      margin-bottom: -3vmin; /* Baseline of logo should be about 5% of short side above edge. */
  }

  .rendered_html img, svg {
      max-height: 440px;
  }

  </style>
</head>
<body>
  <div class="reveal">
    <div class="slides">

<section id="title-slide">
  <h1 class="title">Getting Started with AI on Supercomputers</h1>
  <p class="subtitle">Parallelize Training</p>
  <p class="author">Alexandre Strube // Sabrina Benassou</p>
  <p class="date">December 13, 2023</p>
</section>

<section id="the-resnet50-model" class="slide level2">
<h2>The ResNet50 Model</h2>
<p><img data-src="images/resnet.png" /></p>
</section>
<section id="imagenet-class" class="slide level2">
<h2>ImageNet class</h2>
<div class="sourceCode" id="cb1"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> ImageNet(Dataset):</span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, root, split, transform<span class="op">=</span><span class="va">None</span>):</span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.samples <span class="op">=</span> []</span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.targets <span class="op">=</span> []</span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.transform <span class="op">=</span> transform</span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.syn_to_class <span class="op">=</span> {}</span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a>        <span class="cf">with</span> <span class="bu">open</span>(os.path.join(root, <span class="st">&quot;imagenet_class_index.json&quot;</span>), <span class="st">&quot;rb&quot;</span>) <span class="im">as</span> f:</span>
<span id="cb1-8"><a href="#cb1-8" aria-hidden="true" tabindex="-1"></a>                    json_file <span class="op">=</span> json.load(f)</span>
<span id="cb1-9"><a href="#cb1-9" aria-hidden="true" tabindex="-1"></a>                    <span class="cf">for</span> class_id, v <span class="kw">in</span> json_file.items():</span>
<span id="cb1-10"><a href="#cb1-10" aria-hidden="true" tabindex="-1"></a>                        <span class="va">self</span>.syn_to_class[v[<span class="dv">0</span>]] <span class="op">=</span> <span class="bu">int</span>(class_id)</span>
<span id="cb1-11"><a href="#cb1-11" aria-hidden="true" tabindex="-1"></a>        <span class="cf">with</span> <span class="bu">open</span>(os.path.join(root, <span class="st">&quot;ILSVRC2012_val_labels.json&quot;</span>), <span class="st">&quot;rb&quot;</span>) <span class="im">as</span> f:</span>
<span id="cb1-12"><a href="#cb1-12" aria-hidden="true" tabindex="-1"></a>                    <span class="va">self</span>.val_to_syn <span class="op">=</span> json.load(f)</span>
<span id="cb1-13"><a href="#cb1-13" aria-hidden="true" tabindex="-1"></a>        samples_dir <span class="op">=</span> os.path.join(root, <span class="st">&quot;ILSVRC/Data/CLS-LOC&quot;</span>, split)</span>
<span id="cb1-14"><a href="#cb1-14" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> entry <span class="kw">in</span> os.listdir(samples_dir):</span>
<span id="cb1-15"><a href="#cb1-15" aria-hidden="true" tabindex="-1"></a>            <span class="cf">if</span> split <span class="op">==</span> <span class="st">&quot;train&quot;</span>:</span>
<span id="cb1-16"><a href="#cb1-16" aria-hidden="true" tabindex="-1"></a>                syn_id <span class="op">=</span> entry</span>
<span id="cb1-17"><a href="#cb1-17" aria-hidden="true" tabindex="-1"></a>                target <span class="op">=</span> <span class="va">self</span>.syn_to_class[syn_id]</span>
<span id="cb1-18"><a href="#cb1-18" aria-hidden="true" tabindex="-1"></a>                syn_folder <span class="op">=</span> os.path.join(samples_dir, syn_id)</span>
<span id="cb1-19"><a href="#cb1-19" aria-hidden="true" tabindex="-1"></a>                <span class="cf">for</span> sample <span class="kw">in</span> os.listdir(syn_folder):</span>
<span id="cb1-20"><a href="#cb1-20" aria-hidden="true" tabindex="-1"></a>                    sample_path <span class="op">=</span> os.path.join(syn_folder, sample)</span>
<span id="cb1-21"><a href="#cb1-21" aria-hidden="true" tabindex="-1"></a>                    <span class="va">self</span>.samples.append(sample_path)</span>
<span id="cb1-22"><a href="#cb1-22" aria-hidden="true" tabindex="-1"></a>                    <span class="va">self</span>.targets.append(target)</span>
<span id="cb1-23"><a href="#cb1-23" aria-hidden="true" tabindex="-1"></a>            <span class="cf">elif</span> split <span class="op">==</span> <span class="st">&quot;val&quot;</span>:</span>
<span id="cb1-24"><a href="#cb1-24" aria-hidden="true" tabindex="-1"></a>                syn_id <span class="op">=</span> <span class="va">self</span>.val_to_syn[entry]</span>
<span id="cb1-25"><a href="#cb1-25" aria-hidden="true" tabindex="-1"></a>                target <span class="op">=</span> <span class="va">self</span>.syn_to_class[syn_id]</span>
<span id="cb1-26"><a href="#cb1-26" aria-hidden="true" tabindex="-1"></a>                sample_path <span class="op">=</span> os.path.join(samples_dir, entry)</span>
<span id="cb1-27"><a href="#cb1-27" aria-hidden="true" tabindex="-1"></a>                <span class="va">self</span>.samples.append(sample_path)</span>
<span id="cb1-28"><a href="#cb1-28" aria-hidden="true" tabindex="-1"></a>                <span class="va">self</span>.targets.append(target)    </span>
<span id="cb1-29"><a href="#cb1-29" aria-hidden="true" tabindex="-1"></a>                </span>
<span id="cb1-30"><a href="#cb1-30" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__len__</span>(<span class="va">self</span>):</span>
<span id="cb1-31"><a href="#cb1-31" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> <span class="bu">len</span>(<span class="va">self</span>.samples)    </span>
<span id="cb1-32"><a href="#cb1-32" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb1-33"><a href="#cb1-33" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__getitem__</span>(<span class="va">self</span>, idx):</span>
<span id="cb1-34"><a href="#cb1-34" aria-hidden="true" tabindex="-1"></a>        x <span class="op">=</span> Image.<span class="bu">open</span>(<span class="va">self</span>.samples[idx]).convert(<span class="st">&quot;RGB&quot;</span>)</span>
<span id="cb1-35"><a href="#cb1-35" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> <span class="va">self</span>.transform:</span>
<span id="cb1-36"><a href="#cb1-36" aria-hidden="true" tabindex="-1"></a>            x <span class="op">=</span> <span class="va">self</span>.transform(x)</span>
<span id="cb1-37"><a href="#cb1-37" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> x, <span class="va">self</span>.targets[idx]</span></code></pre></div>
</section>
<section id="pytorch-lightning-data-module" class="slide level2">
<h2>PyTorch Lightning Data Module</h2>
<div class="sourceCode" id="cb2"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> ImageNetDataModule(pl.LightningDataModule):</span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(</span>
<span id="cb2-3"><a href="#cb2-3" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>,</span>
<span id="cb2-4"><a href="#cb2-4" aria-hidden="true" tabindex="-1"></a>        data_root: <span class="bu">str</span>,</span>
<span id="cb2-5"><a href="#cb2-5" aria-hidden="true" tabindex="-1"></a>        batch_size: <span class="bu">int</span>,</span>
<span id="cb2-6"><a href="#cb2-6" aria-hidden="true" tabindex="-1"></a>        num_workers: <span class="bu">int</span>,</span>
<span id="cb2-7"><a href="#cb2-7" aria-hidden="true" tabindex="-1"></a>        dataset_transforms: <span class="bu">dict</span>(),</span>
<span id="cb2-8"><a href="#cb2-8" aria-hidden="true" tabindex="-1"></a>    ):</span>
<span id="cb2-9"><a href="#cb2-9" aria-hidden="true" tabindex="-1"></a>        <span class="bu">super</span>().<span class="fu">__init__</span>()</span>
<span id="cb2-10"><a href="#cb2-10" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.data_root <span class="op">=</span> data_root</span>
<span id="cb2-11"><a href="#cb2-11" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.batch_size <span class="op">=</span> batch_size</span>
<span id="cb2-12"><a href="#cb2-12" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.num_workers <span class="op">=</span> num_workers</span>
<span id="cb2-13"><a href="#cb2-13" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.dataset_transforms <span class="op">=</span> dataset_transforms</span>
<span id="cb2-14"><a href="#cb2-14" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb2-15"><a href="#cb2-15" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> setup(<span class="va">self</span>, stage: Optional[<span class="bu">str</span>] <span class="op">=</span> <span class="va">None</span>):</span>
<span id="cb2-16"><a href="#cb2-16" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.train <span class="op">=</span> ImageNet(<span class="va">self</span>.data_root, <span class="st">&quot;train&quot;</span>, <span class="va">self</span>.dataset_transforms)</span>
<span id="cb2-17"><a href="#cb2-17" aria-hidden="true" tabindex="-1"></a>            </span>
<span id="cb2-18"><a href="#cb2-18" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> train_dataloader(<span class="va">self</span>):</span>
<span id="cb2-19"><a href="#cb2-19" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> DataLoader(<span class="va">self</span>.train, batch_size<span class="op">=</span><span class="va">self</span>.batch_size, <span class="op">\</span></span>
<span id="cb2-20"><a href="#cb2-20" aria-hidden="true" tabindex="-1"></a>            num_workers<span class="op">=</span><span class="va">self</span>.num_workers)</span></code></pre></div>
</section>
<section id="pytorch-lightning-module" class="slide level2">
<h2>PyTorch Lightning Module</h2>
<div class="sourceCode" id="cb3"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> resnet50Model(pl.LightningModule):</span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>):</span>
<span id="cb3-3"><a href="#cb3-3" aria-hidden="true" tabindex="-1"></a>        <span class="bu">super</span>().<span class="fu">__init__</span>()</span>
<span id="cb3-4"><a href="#cb3-4" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.model <span class="op">=</span> resnet50(pretrained<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb3-5"><a href="#cb3-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-6"><a href="#cb3-6" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> forward(<span class="va">self</span>, x):</span>
<span id="cb3-7"><a href="#cb3-7" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> <span class="va">self</span>.model(x)</span>
<span id="cb3-8"><a href="#cb3-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-9"><a href="#cb3-9" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> training_step(<span class="va">self</span>,batch):</span>
<span id="cb3-10"><a href="#cb3-10" aria-hidden="true" tabindex="-1"></a>        x, labels <span class="op">=</span> batch</span>
<span id="cb3-11"><a href="#cb3-11" aria-hidden="true" tabindex="-1"></a>        pred<span class="op">=</span><span class="va">self</span>.forward(x)</span>
<span id="cb3-12"><a href="#cb3-12" aria-hidden="true" tabindex="-1"></a>        train_loss <span class="op">=</span> F.cross_entropy(pred, labels)</span>
<span id="cb3-13"><a href="#cb3-13" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.log(<span class="st">&quot;training_loss&quot;</span>, train_loss)</span>
<span id="cb3-14"><a href="#cb3-14" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb3-15"><a href="#cb3-15" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> train_loss</span>
<span id="cb3-16"><a href="#cb3-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-17"><a href="#cb3-17" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> configure_optimizers(<span class="va">self</span>):</span>
<span id="cb3-18"><a href="#cb3-18" aria-hidden="true" tabindex="-1"></a>            <span class="cf">return</span> torch.optim.Adam(<span class="va">self</span>.parameters(), lr<span class="op">=</span><span class="fl">0.02</span>)</span></code></pre></div>
</section>
<section id="one-gpu-training" class="slide level2">
<h2>One GPU training</h2>
<div class="sourceCode" id="cb4"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a>transform <span class="op">=</span> transforms.Compose([</span>
<span id="cb4-2"><a href="#cb4-2" aria-hidden="true" tabindex="-1"></a>    transforms.ToTensor(),</span>
<span id="cb4-3"><a href="#cb4-3" aria-hidden="true" tabindex="-1"></a>    transforms.Resize((<span class="dv">256</span>, <span class="dv">256</span>))</span>
<span id="cb4-4"><a href="#cb4-4" aria-hidden="true" tabindex="-1"></a>])</span>
<span id="cb4-5"><a href="#cb4-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-6"><a href="#cb4-6" aria-hidden="true" tabindex="-1"></a><span class="co"># 1. Organize the data</span></span>
<span id="cb4-7"><a href="#cb4-7" aria-hidden="true" tabindex="-1"></a>datamodule <span class="op">=</span> ImageNetDataModule(<span class="st">&quot;/p/scratch/training2402/data/&quot;</span>, <span class="dv">256</span>, <span class="op">\</span></span>
<span id="cb4-8"><a href="#cb4-8" aria-hidden="true" tabindex="-1"></a>    <span class="bu">int</span>(os.getenv(<span class="st">&#39;SLURM_CPUS_PER_TASK&#39;</span>)), transform)</span>
<span id="cb4-9"><a href="#cb4-9" aria-hidden="true" tabindex="-1"></a><span class="co"># 2. Build the model using desired Task</span></span>
<span id="cb4-10"><a href="#cb4-10" aria-hidden="true" tabindex="-1"></a>model <span class="op">=</span> resnet50Model()</span>
<span id="cb4-11"><a href="#cb4-11" aria-hidden="true" tabindex="-1"></a><span class="co"># 3. Create the trainer</span></span>
<span id="cb4-12"><a href="#cb4-12" aria-hidden="true" tabindex="-1"></a>trainer <span class="op">=</span> pl.Trainer(max_epochs<span class="op">=</span><span class="dv">10</span>,  accelerator<span class="op">=</span><span class="st">&quot;gpu&quot;</span>)</span>
<span id="cb4-13"><a href="#cb4-13" aria-hidden="true" tabindex="-1"></a><span class="co"># 4. Train the model</span></span>
<span id="cb4-14"><a href="#cb4-14" aria-hidden="true" tabindex="-1"></a>trainer.fit(model, datamodule<span class="op">=</span>datamodule)</span>
<span id="cb4-15"><a href="#cb4-15" aria-hidden="true" tabindex="-1"></a><span class="co"># 5. Save the model!</span></span>
<span id="cb4-16"><a href="#cb4-16" aria-hidden="true" tabindex="-1"></a>trainer.save_checkpoint(<span class="st">&quot;image_classification_model.pt&quot;</span>)</span></code></pre></div>
</section>
<section id="one-gpu-training-1" class="slide level2">
<h2>One GPU training</h2>
<div class="sourceCode" id="cb5"><pre
class="sourceCode bash"><code class="sourceCode bash"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a><span class="co">#!/bin/bash -x</span></span>
<span id="cb5-2"><a href="#cb5-2" aria-hidden="true" tabindex="-1"></a><span class="co">#SBATCH --nodes=1            </span></span>
<span id="cb5-3"><a href="#cb5-3" aria-hidden="true" tabindex="-1"></a><span class="co">#SBATCH --gres=gpu:1</span></span>
<span id="cb5-4"><a href="#cb5-4" aria-hidden="true" tabindex="-1"></a><span class="co">#SBATCH --ntasks-per-node=1  </span></span>
<span id="cb5-5"><a href="#cb5-5" aria-hidden="true" tabindex="-1"></a><span class="co">#SBATCH --cpus-per-task=96</span></span>
<span id="cb5-6"><a href="#cb5-6" aria-hidden="true" tabindex="-1"></a><span class="co">#SBATCH --time=06:00:00</span></span>
<span id="cb5-7"><a href="#cb5-7" aria-hidden="true" tabindex="-1"></a><span class="co">#SBATCH --partition=booster</span></span>
<span id="cb5-8"><a href="#cb5-8" aria-hidden="true" tabindex="-1"></a><span class="co">#SBATCH --account=training2402</span></span>
<span id="cb5-9"><a href="#cb5-9" aria-hidden="true" tabindex="-1"></a><span class="co">#SBATCH --output=%j.out</span></span>
<span id="cb5-10"><a href="#cb5-10" aria-hidden="true" tabindex="-1"></a><span class="co">#SBATCH --error=%j.err</span></span>
<span id="cb5-11"><a href="#cb5-11" aria-hidden="true" tabindex="-1"></a><span class="co">#SBATCH --reservation=training-booster-2024-03-13 </span></span>
<span id="cb5-12"><a href="#cb5-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-13"><a href="#cb5-13" aria-hidden="true" tabindex="-1"></a><span class="co"># To get number of cpu per task</span></span>
<span id="cb5-14"><a href="#cb5-14" aria-hidden="true" tabindex="-1"></a><span class="bu">export</span> <span class="va">SRUN_CPUS_PER_TASK</span><span class="op">=</span><span class="st">&quot;</span><span class="va">$SLURM_CPUS_PER_TASK</span><span class="st">&quot;</span></span>
<span id="cb5-15"><a href="#cb5-15" aria-hidden="true" tabindex="-1"></a><span class="co"># activate env</span></span>
<span id="cb5-16"><a href="#cb5-16" aria-hidden="true" tabindex="-1"></a><span class="bu">source</span> <span class="va">$HOME</span>/course/<span class="va">$USER</span>/sc_venv_template/activate.sh</span>
<span id="cb5-17"><a href="#cb5-17" aria-hidden="true" tabindex="-1"></a><span class="co"># run script from above</span></span>
<span id="cb5-18"><a href="#cb5-18" aria-hidden="true" tabindex="-1"></a><span class="bu">time</span> srun python3 gpu_training.py</span></code></pre></div>
<div class="sourceCode" id="cb6"><pre
class="sourceCode bash"><code class="sourceCode bash"><span id="cb6-1"><a href="#cb6-1" aria-hidden="true" tabindex="-1"></a><span class="ex">real</span>    342m11.864s</span></code></pre></div>
</section>
<section id="demo" class="slide level2">
<h2>DEMO</h2>
</section>
<section id="but-what-about-many-gpus" class="slide level2">
<h2>But what about many GPUs?</h2>
<ul>
<li class="fragment">It’s when things get interesting</li>
</ul>
</section>
<section id="data-parallel" class="slide level2">
<h2>Data Parallel</h2>
<p><img data-src="images/data-parallel.svg" /></p>
</section>
<section id="data-parallel-1" class="slide level2">
<h2>Data Parallel</h2>
<p><img data-src="images/data-parallel-multiple-data.svg" /></p>
</section>
<section id="data-parallel---averaging" class="slide level2">
<h2>Data Parallel - Averaging</h2>
<p><img data-src="images/data-parallel-averaging.svg" /></p>
</section>
<section id="multi-gpu-training" class="slide level2">
<h2>Multi-GPU training</h2>
<p>1 node and 4 GPU</p>
<div class="sourceCode" id="cb7"><pre
class="sourceCode bash"><code class="sourceCode bash"><span id="cb7-1"><a href="#cb7-1" aria-hidden="true" tabindex="-1"></a><span class="co">#!/bin/bash -x</span></span>
<span id="cb7-2"><a href="#cb7-2" aria-hidden="true" tabindex="-1"></a><span class="co">#SBATCH --nodes=1                     </span></span>
<span id="cb7-3"><a href="#cb7-3" aria-hidden="true" tabindex="-1"></a><span class="co">#SBATCH --gres=gpu:4                  # Use the 4 GPUs available</span></span>
<span id="cb7-4"><a href="#cb7-4" aria-hidden="true" tabindex="-1"></a><span class="co">#SBATCH --ntasks-per-node=4           # When using pl it should always be set to 4</span></span>
<span id="cb7-5"><a href="#cb7-5" aria-hidden="true" tabindex="-1"></a><span class="co">#SBATCH --cpus-per-task=24            # Divide the number of cpus (96) by the number of GPUs (4)</span></span>
<span id="cb7-6"><a href="#cb7-6" aria-hidden="true" tabindex="-1"></a><span class="co">#SBATCH --time=02:00:00</span></span>
<span id="cb7-7"><a href="#cb7-7" aria-hidden="true" tabindex="-1"></a><span class="co">#SBATCH --partition=booster</span></span>
<span id="cb7-8"><a href="#cb7-8" aria-hidden="true" tabindex="-1"></a><span class="co">#SBATCH --account=training2402</span></span>
<span id="cb7-9"><a href="#cb7-9" aria-hidden="true" tabindex="-1"></a><span class="co">#SBATCH --output=%j.out</span></span>
<span id="cb7-10"><a href="#cb7-10" aria-hidden="true" tabindex="-1"></a><span class="co">#SBATCH --error=%j.err</span></span>
<span id="cb7-11"><a href="#cb7-11" aria-hidden="true" tabindex="-1"></a><span class="co">#SBATCH --reservation=training-booster-2024-03-13 </span></span>
<span id="cb7-12"><a href="#cb7-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-13"><a href="#cb7-13" aria-hidden="true" tabindex="-1"></a><span class="bu">export</span> <span class="va">CUDA_VISIBLE_DEVICES</span><span class="op">=</span>0,1,2,3    <span class="co"># Very important to make the GPUs visible</span></span>
<span id="cb7-14"><a href="#cb7-14" aria-hidden="true" tabindex="-1"></a><span class="bu">export</span> <span class="va">SRUN_CPUS_PER_TASK</span><span class="op">=</span><span class="st">&quot;</span><span class="va">$SLURM_CPUS_PER_TASK</span><span class="st">&quot;</span></span>
<span id="cb7-15"><a href="#cb7-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-16"><a href="#cb7-16" aria-hidden="true" tabindex="-1"></a><span class="bu">source</span> <span class="va">$HOME</span>/course/<span class="va">$USER</span>/sc_venv_template/activate.sh</span>
<span id="cb7-17"><a href="#cb7-17" aria-hidden="true" tabindex="-1"></a><span class="bu">time</span> srun python3 gpu_training.py</span></code></pre></div>
<div class="sourceCode" id="cb8"><pre
class="sourceCode bash"><code class="sourceCode bash"><span id="cb8-1"><a href="#cb8-1" aria-hidden="true" tabindex="-1"></a><span class="ex">real</span>    89m15.923s</span></code></pre></div>
</section>
<section id="demo-1" class="slide level2">
<h2>DEMO</h2>
</section>
<section id="thats-it-for-data-parallel" class="slide level2">
<h2>That’s it for data parallel!</h2>
<ul>
<li class="fragment">Copy of the model on each GPU</li>
<li class="fragment">Use different data for each GPU</li>
<li class="fragment">Everything else is the same</li>
<li class="fragment">Average after each iteration</li>
<li class="fragment">Update of the weights</li>
</ul>
</section>
<section id="there-are-more-levels" class="slide level2">
<h2>There are more levels!</h2>
<p><img data-src="images/lets-go-deeper.jpg" /></p>
</section>
<section id="data-parallel---multi-node" class="slide level2">
<h2>Data Parallel - Multi Node</h2>
<p><img data-src="images/data-parallel-multi-node.svg" /></p>
</section>
<section id="data-parallel---multi-node-1" class="slide level2">
<h2>Data Parallel - Multi Node</h2>
<p><img data-src="images/data-parallel-multi-node-averaging.svg" /></p>
</section>
<section id="before-we-go-further" class="slide level2">
<h2>Before we go further…</h2>
<ul>
<li class="fragment">Data parallel is usually good enough 👌</li>
<li class="fragment">If you need more than this, you should be giving
this course, not me 🤷‍♂️</li>
</ul>
</section>
<section id="model-parallel" class="slide level2">
<h2>Model Parallel</h2>
<ul>
<li class="fragment">Model <em>itself</em> is too big to fit in one
single GPU 🐋</li>
<li class="fragment">Each GPU holds a slice of the model 🍕</li>
<li class="fragment">Data moves from one GPU to the next</li>
</ul>
</section>
<section id="model-parallel-1" class="slide level2">
<h2>Model Parallel</h2>
<p><img data-src="images/model-parallel.svg" /></p>
</section>
<section id="model-parallel-2" class="slide level2">
<h2>Model Parallel</h2>
<p><img data-src="images/model-parallel-pipeline-1.svg" /></p>
</section>
<section id="model-parallel-3" class="slide level2">
<h2>Model Parallel</h2>
<p><img data-src="images/model-parallel-pipeline-2.svg" /></p>
</section>
<section id="model-parallel-4" class="slide level2">
<h2>Model Parallel</h2>
<p><img data-src="images/model-parallel-pipeline-3.svg" /></p>
</section>
<section id="model-parallel-5" class="slide level2">
<h2>Model Parallel</h2>
<p><img data-src="images/model-parallel-pipeline-4.svg" /></p>
</section>
<section id="model-parallel-6" class="slide level2">
<h2>Model Parallel</h2>
<p><img data-src="images/model-parallel-pipeline-5.svg" /></p>
</section>
<section id="model-parallel-7" class="slide level2">
<h2>Model Parallel</h2>
<p><img data-src="images/model-parallel-pipeline-6.svg" /></p>
</section>
<section id="model-parallel-8" class="slide level2">
<h2>Model Parallel</h2>
<p><img data-src="images/model-parallel-pipeline-7.svg" /></p>
</section>
<section id="model-parallel-9" class="slide level2">
<h2>Model Parallel</h2>
<p><img data-src="images/model-parallel-pipeline-8.svg" /></p>
</section>
<section id="model-parallel-10" class="slide level2">
<h2>Model Parallel</h2>
<p><img data-src="images/model-parallel-pipeline-9.svg" /></p>
</section>
<section id="model-parallel-11" class="slide level2">
<h2>Model Parallel</h2>
<p><img data-src="images/model-parallel-pipeline-10.svg" /></p>
</section>
<section id="whats-the-problem-here" class="slide level2">
<h2>What’s the problem here? 🧐</h2>
</section>
<section id="model-parallel-12" class="slide level2">
<h2>Model Parallel</h2>
<ul>
<li class="fragment">Waste of resources</li>
<li class="fragment">While one GPU is working, others are waiting the
whole process to end</li>
<li class="fragment"><img data-src="images/no_pipe.png" />
<ul>
<li class="fragment"><a href="https://arxiv.org/abs/1811.06965">Source:
GPipe: Efficient Training of Giant Neural Networks using Pipeline
Parallelism</a></li>
</ul></li>
</ul>
</section>
<section id="model-parallel---pipelining" class="slide level2">
<h2>Model Parallel - Pipelining</h2>
<p><img data-src="images/model-parallel-pipeline-1.svg" /></p>
</section>
<section id="model-parallel---pipelining-1" class="slide level2">
<h2>Model Parallel - Pipelining</h2>
<p><img
data-src="images/model-parallel-pipeline-2-multibatch.svg" /></p>
</section>
<section id="model-parallel---pipelining-2" class="slide level2">
<h2>Model Parallel - Pipelining</h2>
<p><img
data-src="images/model-parallel-pipeline-3-multibatch.svg" /></p>
</section>
<section id="model-parallel---pipelining-3" class="slide level2">
<h2>Model Parallel - Pipelining</h2>
<p><img
data-src="images/model-parallel-pipeline-4-multibatch.svg" /></p>
</section>
<section id="model-parallel---pipelining-4" class="slide level2">
<h2>Model Parallel - Pipelining</h2>
<p><img
data-src="images/model-parallel-pipeline-5-multibatch.svg" /></p>
</section>
<section id="model-parallel---pipelining-5" class="slide level2">
<h2>Model Parallel - Pipelining</h2>
<p><img
data-src="images/model-parallel-pipeline-6-multibatch.svg" /></p>
</section>
<section id="model-parallel---pipelining-6" class="slide level2">
<h2>Model Parallel - Pipelining</h2>
<p><img
data-src="images/model-parallel-pipeline-7-multibatch.svg" /></p>
</section>
<section id="model-parallel---pipelining-7" class="slide level2">
<h2>Model Parallel - Pipelining</h2>
<p><img
data-src="images/model-parallel-pipeline-8-multibatch.svg" /></p>
</section>
<section id="model-parallel---pipelining-8" class="slide level2">
<h2>Model Parallel - Pipelining</h2>
<p><img
data-src="images/model-parallel-pipeline-9-multibatch.svg" /></p>
</section>
<section id="this-is-an-oversimplification" class="slide level2">
<h2>This is an oversimplification!</h2>
<ul>
<li class="fragment">Actually, you split the input minibatch into
multiple microbatches.</li>
<li class="fragment">There’s still idle time - an unavoidable “bubble”
🫧</li>
<li class="fragment"><img data-src="images/pipe.png" /></li>
</ul>
</section>
<section id="model-parallel---multi-node" class="slide level2">
<h2>Model Parallel - Multi Node</h2>
<ul>
<li class="fragment">In this case, each node does the same as the
others.</li>
<li class="fragment">At each step, they all synchronize their
weights.</li>
</ul>
</section>
<section id="model-parallel---multi-node-1" class="slide level2">
<h2>Model Parallel - Multi Node</h2>
<p><img data-src="images/model-parallel-multi-node.svg" /></p>
</section>
<section id="model-parallel---going-bigger" class="slide level2">
<h2>Model Parallel - going bigger</h2>
<ul>
<li class="fragment">You can also have layers spreaded over multiple
gpus</li>
<li class="fragment">One can even pipeline among nodes….</li>
</ul>
</section>
<section id="recap" class="slide level2">
<h2>Recap</h2>
<ul>
<li class="fragment">Data parallelism:
<ul>
<li class="fragment">Split the data over multiple GPUs</li>
<li class="fragment">Each GPU runs the whole model</li>
<li class="fragment">The gradients are averaged at each step</li>
<li class="fragment">Update of the model’s weights</li>
</ul></li>
<li class="fragment">Data parallelism, multi-node:
<ul>
<li class="fragment">Same, but gradients are averaged across nodes</li>
</ul></li>
<li class="fragment">Model parallelism:
<ul>
<li class="fragment">Split the model over multiple GPUs</li>
<li class="fragment">Each GPU does the forward/backward pass</li>
</ul></li>
<li class="fragment">Model parallelism, multi-node:
<ul>
<li class="fragment">Same, but gradients are averaged across nodes</li>
</ul></li>
</ul>
</section>
<section id="parallel-training-with-pytorch-ddp" class="slide level2">
<h2>Parallel Training with PyTorch DDP</h2>
<ul>
<li class="fragment"><a
href="https://lightning.ai/docs/pytorch/stable/accelerators/gpu_intermediate.html">PyTorch’s
DDP (Distributed Data Parallel)</a> works as follows:
<ul>
<li class="fragment">Each GPU across each node gets its own
process.</li>
<li class="fragment">Each GPU gets visibility into a subset of the
overall dataset. It will only ever see that subset.</li>
<li class="fragment">Each process inits the model.</li>
<li class="fragment">Each process performs a full forward and backward
pass in parallel.</li>
<li class="fragment">The gradients are synced and averaged across all
processes.</li>
<li class="fragment">Each process updates its optimizer.</li>
</ul></li>
</ul>
</section>
<section id="terminologies" class="slide level2">
<h2>Terminologies</h2>
<ul>
<li class="fragment">WORLD_SIZE: number of processes participating in
the job.</li>
<li class="fragment">RANK: the rank of the process in the network.</li>
<li class="fragment">LOCAL_RANK: the rank of the process on the local
machine.</li>
<li class="fragment">MASTER_PORT: free port on machine with rank 0.
<!-- - MASTER_ADDR: address of rank 0 node. --></li>
</ul>
</section>
<section id="ddp-steps" class="slide level2">
<h2>DDP steps</h2>
<ol type="1">
<li class="fragment">Set up the environement variables for the
distributed mode (WORLD_SIZE, RANK, LOCAL_RANK …)</li>
</ol>
<ul>
<li class="fragment"><div class="sourceCode" id="cb9"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb9-1"><a href="#cb9-1" aria-hidden="true" tabindex="-1"></a><span class="co"># The number of total processes started by Slurm.</span></span>
<span id="cb9-2"><a href="#cb9-2" aria-hidden="true" tabindex="-1"></a>ntasks <span class="op">=</span> os.getenv(<span class="st">&#39;SLURM_NTASKS&#39;</span>)</span>
<span id="cb9-3"><a href="#cb9-3" aria-hidden="true" tabindex="-1"></a><span class="co"># Index of the current process.</span></span>
<span id="cb9-4"><a href="#cb9-4" aria-hidden="true" tabindex="-1"></a>rank <span class="op">=</span> os.getenv(<span class="st">&#39;SLURM_PROCID&#39;</span>)</span>
<span id="cb9-5"><a href="#cb9-5" aria-hidden="true" tabindex="-1"></a><span class="co"># Index of the current process on this node only.</span></span>
<span id="cb9-6"><a href="#cb9-6" aria-hidden="true" tabindex="-1"></a>local_rank <span class="op">=</span> os.getenv(<span class="st">&#39;SLURM_LOCALID&#39;</span>)</span>
<span id="cb9-7"><a href="#cb9-7" aria-hidden="true" tabindex="-1"></a><span class="co"># The number of nodes</span></span>
<span id="cb9-8"><a href="#cb9-8" aria-hidden="true" tabindex="-1"></a>nnodes <span class="op">=</span> os.getenv(<span class="st">&quot;SLURM_NNODES&quot;</span>)</span></code></pre></div></li>
</ul>
</section>
<section id="ddp-steps-1" class="slide level2">
<h2>DDP steps</h2>
<ol start="2" type="1">
<li class="fragment">Initialize a sampler to specify the sequence of
indices/keys used in data loading.</li>
<li class="fragment">Implements data parallelism of the model.</li>
<li class="fragment">Allow only one process to save checkpoints.</li>
</ol>
<ul>
<li class="fragment"><div class="sourceCode" id="cb10"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb10-1"><a href="#cb10-1" aria-hidden="true" tabindex="-1"></a>datamodule <span class="op">=</span> ImageNetDataModule(<span class="st">&quot;/p/scratch/training2402/data/&quot;</span>, <span class="dv">256</span>, <span class="op">\</span></span>
<span id="cb10-2"><a href="#cb10-2" aria-hidden="true" tabindex="-1"></a>    <span class="bu">int</span>(os.getenv(<span class="st">&#39;SLURM_CPUS_PER_TASK&#39;</span>)), transform)</span>
<span id="cb10-3"><a href="#cb10-3" aria-hidden="true" tabindex="-1"></a>trainer <span class="op">=</span> pl.Trainer(max_epochs<span class="op">=</span><span class="dv">10</span>,  accelerator<span class="op">=</span><span class="st">&quot;gpu&quot;</span>, num_nodes<span class="op">=</span>nnodes)</span>
<span id="cb10-4"><a href="#cb10-4" aria-hidden="true" tabindex="-1"></a>trainer.fit(model, datamodule<span class="op">=</span>datamodule)</span>
<span id="cb10-5"><a href="#cb10-5" aria-hidden="true" tabindex="-1"></a>trainer.save_checkpoint(<span class="st">&quot;image_classification_model.pt&quot;</span>)</span></code></pre></div></li>
</ul>
</section>
<section id="ddp-steps-2" class="slide level2">
<h2>DDP steps</h2>
<div class="sourceCode" id="cb11"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb11-1"><a href="#cb11-1" aria-hidden="true" tabindex="-1"></a>transform <span class="op">=</span> transforms.Compose([</span>
<span id="cb11-2"><a href="#cb11-2" aria-hidden="true" tabindex="-1"></a>    transforms.ToTensor(),</span>
<span id="cb11-3"><a href="#cb11-3" aria-hidden="true" tabindex="-1"></a>    transforms.Resize((<span class="dv">256</span>, <span class="dv">256</span>))</span>
<span id="cb11-4"><a href="#cb11-4" aria-hidden="true" tabindex="-1"></a>])</span>
<span id="cb11-5"><a href="#cb11-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-6"><a href="#cb11-6" aria-hidden="true" tabindex="-1"></a><span class="co"># 1. The number of nodes</span></span>
<span id="cb11-7"><a href="#cb11-7" aria-hidden="true" tabindex="-1"></a>nnodes <span class="op">=</span> os.getenv(<span class="st">&quot;SLURM_NNODES&quot;</span>)</span>
<span id="cb11-8"><a href="#cb11-8" aria-hidden="true" tabindex="-1"></a><span class="co"># 2. Organize the data</span></span>
<span id="cb11-9"><a href="#cb11-9" aria-hidden="true" tabindex="-1"></a>datamodule <span class="op">=</span> ImageNetDataModule(<span class="st">&quot;/p/scratch/training2402/data/&quot;</span>, <span class="dv">128</span>, <span class="op">\</span></span>
<span id="cb11-10"><a href="#cb11-10" aria-hidden="true" tabindex="-1"></a>    <span class="bu">int</span>(os.getenv(<span class="st">&#39;SLURM_CPUS_PER_TASK&#39;</span>)), transform)</span>
<span id="cb11-11"><a href="#cb11-11" aria-hidden="true" tabindex="-1"></a><span class="co"># 3. Build the model using desired Task</span></span>
<span id="cb11-12"><a href="#cb11-12" aria-hidden="true" tabindex="-1"></a>model <span class="op">=</span> resnet50Model()</span>
<span id="cb11-13"><a href="#cb11-13" aria-hidden="true" tabindex="-1"></a><span class="co"># 4. Create the trainer</span></span>
<span id="cb11-14"><a href="#cb11-14" aria-hidden="true" tabindex="-1"></a>trainer <span class="op">=</span> pl.Trainer(max_epochs<span class="op">=</span><span class="dv">10</span>,  accelerator<span class="op">=</span><span class="st">&quot;gpu&quot;</span>, num_nodes<span class="op">=</span>nnodes)</span>
<span id="cb11-15"><a href="#cb11-15" aria-hidden="true" tabindex="-1"></a><span class="co"># 5. Train the model</span></span>
<span id="cb11-16"><a href="#cb11-16" aria-hidden="true" tabindex="-1"></a>trainer.fit(model, datamodule<span class="op">=</span>datamodule)</span>
<span id="cb11-17"><a href="#cb11-17" aria-hidden="true" tabindex="-1"></a><span class="co"># 6. Save the model!</span></span>
<span id="cb11-18"><a href="#cb11-18" aria-hidden="true" tabindex="-1"></a>trainer.save_checkpoint(<span class="st">&quot;image_classification_model.pt&quot;</span>)</span></code></pre></div>
</section>
<section id="ddp-training" class="slide level2">
<h2>DDP training</h2>
<p>16 nodes and 4 GPU each</p>
<div class="sourceCode" id="cb12"><pre
class="sourceCode bash"><code class="sourceCode bash"><span id="cb12-1"><a href="#cb12-1" aria-hidden="true" tabindex="-1"></a><span class="co">#!/bin/bash -x</span></span>
<span id="cb12-2"><a href="#cb12-2" aria-hidden="true" tabindex="-1"></a><span class="co">#SBATCH --nodes=16                     # This needs to match Trainer(num_nodes=...)</span></span>
<span id="cb12-3"><a href="#cb12-3" aria-hidden="true" tabindex="-1"></a><span class="co">#SBATCH --gres=gpu:4                   # Use the 4 GPUs available</span></span>
<span id="cb12-4"><a href="#cb12-4" aria-hidden="true" tabindex="-1"></a><span class="co">#SBATCH --ntasks-per-node=4            # When using pl it should always be set to 4</span></span>
<span id="cb12-5"><a href="#cb12-5" aria-hidden="true" tabindex="-1"></a><span class="co">#SBATCH --cpus-per-task=24             # Divide the number of cpus (96) by the number of GPUs (4)</span></span>
<span id="cb12-6"><a href="#cb12-6" aria-hidden="true" tabindex="-1"></a><span class="co">#SBATCH --time=00:15:00</span></span>
<span id="cb12-7"><a href="#cb12-7" aria-hidden="true" tabindex="-1"></a><span class="co">#SBATCH --partition=booster</span></span>
<span id="cb12-8"><a href="#cb12-8" aria-hidden="true" tabindex="-1"></a><span class="co">#SBATCH --account=training2402</span></span>
<span id="cb12-9"><a href="#cb12-9" aria-hidden="true" tabindex="-1"></a><span class="co">#SBATCH --output=%j.out</span></span>
<span id="cb12-10"><a href="#cb12-10" aria-hidden="true" tabindex="-1"></a><span class="co">#SBATCH --error=%j.err</span></span>
<span id="cb12-11"><a href="#cb12-11" aria-hidden="true" tabindex="-1"></a><span class="co">#SBATCH --reservation=training-booster-2024-03-13 </span></span>
<span id="cb12-12"><a href="#cb12-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-13"><a href="#cb12-13" aria-hidden="true" tabindex="-1"></a><span class="bu">export</span> <span class="va">CUDA_VISIBLE_DEVICES</span><span class="op">=</span>0,1,2,3    <span class="co"># Very important to make the GPUs visible</span></span>
<span id="cb12-14"><a href="#cb12-14" aria-hidden="true" tabindex="-1"></a><span class="bu">export</span> <span class="va">SRUN_CPUS_PER_TASK</span><span class="op">=</span><span class="st">&quot;</span><span class="va">$SLURM_CPUS_PER_TASK</span><span class="st">&quot;</span></span>
<span id="cb12-15"><a href="#cb12-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-16"><a href="#cb12-16" aria-hidden="true" tabindex="-1"></a><span class="bu">source</span> <span class="va">$HOME</span>/course/<span class="va">$USER</span>/sc_venv_template/activate.sh</span>
<span id="cb12-17"><a href="#cb12-17" aria-hidden="true" tabindex="-1"></a><span class="bu">time</span> srun python3 ddp_training.py</span></code></pre></div>
<div class="sourceCode" id="cb13"><pre
class="sourceCode bash"><code class="sourceCode bash"><span id="cb13-1"><a href="#cb13-1" aria-hidden="true" tabindex="-1"></a><span class="ex">real</span>    6m56.457s</span></code></pre></div>
</section>
<section id="ddp-training-1" class="slide level2">
<h2>DDP training</h2>
<p>With 4 nodes:</p>
<div class="sourceCode" id="cb14"><pre
class="sourceCode bash"><code class="sourceCode bash"><span id="cb14-1"><a href="#cb14-1" aria-hidden="true" tabindex="-1"></a><span class="ex">real</span>    24m48.169s</span></code></pre></div>
<p>With 8 nodes:</p>
<div class="sourceCode" id="cb15"><pre
class="sourceCode bash"><code class="sourceCode bash"><span id="cb15-1"><a href="#cb15-1" aria-hidden="true" tabindex="-1"></a><span class="ex">real</span>    13m10.722s</span></code></pre></div>
<p>With 16 nodes:</p>
<div class="sourceCode" id="cb16"><pre
class="sourceCode bash"><code class="sourceCode bash"><span id="cb16-1"><a href="#cb16-1" aria-hidden="true" tabindex="-1"></a><span class="ex">real</span>    6m56.457s</span></code></pre></div>
<p>With 32 nodes:</p>
<div class="sourceCode" id="cb17"><pre
class="sourceCode bash"><code class="sourceCode bash"><span id="cb17-1"><a href="#cb17-1" aria-hidden="true" tabindex="-1"></a><span class="ex">real</span>    4m48.313s</span></code></pre></div>
</section>
<section id="data-parallel-2" class="slide level2">
<h2>Data Parallel</h2>
<!-- What changed? -->
<ul>
<li class="fragment">It was</li>
<li class="fragment"><div class="sourceCode" id="cb18"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb18-1"><a href="#cb18-1" aria-hidden="true" tabindex="-1"></a>trainer <span class="op">=</span> pl.Trainer(max_epochs<span class="op">=</span><span class="dv">10</span>,  accelerator<span class="op">=</span><span class="st">&quot;gpu&quot;</span>)</span></code></pre></div></li>
<li class="fragment">Became</li>
<li class="fragment"><div class="sourceCode" id="cb19"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb19-1"><a href="#cb19-1" aria-hidden="true" tabindex="-1"></a>nnodes <span class="op">=</span> os.getenv(<span class="st">&quot;SLURM_NNODES&quot;</span>)</span>
<span id="cb19-2"><a href="#cb19-2" aria-hidden="true" tabindex="-1"></a>trainer <span class="op">=</span> pl.Trainer(max_epochs<span class="op">=</span><span class="dv">10</span>,  accelerator<span class="op">=</span><span class="st">&quot;gpu&quot;</span>, num_nodes<span class="op">=</span>nnodes)</span></code></pre></div></li>
</ul>
</section>
<section id="data-parallel-3" class="slide level2">
<h2>Data Parallel</h2>
<!-- What changed? -->
<ul>
<li class="fragment">It was</li>
<li class="fragment"><div class="sourceCode" id="cb20"><pre
class="sourceCode bash"><code class="sourceCode bash"><span id="cb20-1"><a href="#cb20-1" aria-hidden="true" tabindex="-1"></a><span class="co">#SBATCH --nodes=1                </span></span>
<span id="cb20-2"><a href="#cb20-2" aria-hidden="true" tabindex="-1"></a><span class="co">#SBATCH --gres=gpu:1</span></span>
<span id="cb20-3"><a href="#cb20-3" aria-hidden="true" tabindex="-1"></a><span class="co">#SBATCH --ntasks-per-node=1</span></span>
<span id="cb20-4"><a href="#cb20-4" aria-hidden="true" tabindex="-1"></a><span class="co">#SBATCH --cpus-per-task=96</span></span></code></pre></div></li>
<li class="fragment">Became</li>
<li class="fragment"><div class="sourceCode" id="cb21"><pre
class="sourceCode bash"><code class="sourceCode bash"><span id="cb21-1"><a href="#cb21-1" aria-hidden="true" tabindex="-1"></a><span class="co">#SBATCH --nodes=16                   # This needs to match Trainer(num_nodes=...)</span></span>
<span id="cb21-2"><a href="#cb21-2" aria-hidden="true" tabindex="-1"></a><span class="co">#SBATCH --gres=gpu:4                 # Use the 4 GPUs available</span></span>
<span id="cb21-3"><a href="#cb21-3" aria-hidden="true" tabindex="-1"></a><span class="co">#SBATCH --ntasks-per-node=4          # When using pl it should always be set to 4</span></span>
<span id="cb21-4"><a href="#cb21-4" aria-hidden="true" tabindex="-1"></a><span class="co">#SBATCH --cpus-per-task=24           # Divide the number of cpus (96) by the number of GPUs (4)</span></span>
<span id="cb21-5"><a href="#cb21-5" aria-hidden="true" tabindex="-1"></a><span class="bu">export</span> <span class="va">CUDA_VISIBLE_DEVICES</span><span class="op">=</span>0,1,2,3  <span class="co"># Very important to make the GPUs visible</span></span></code></pre></div></li>
</ul>
</section>
<section id="demo-2" class="slide level2">
<h2>DEMO</h2>
</section>
<section id="tensorboard" class="slide level2">
<h2>TensorBoard</h2>
<ul>
<li class="fragment">In resnet50.py</li>
<li class="fragment"><div class="sourceCode" id="cb22"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb22-1"><a href="#cb22-1" aria-hidden="true" tabindex="-1"></a><span class="va">self</span>.log(<span class="st">&quot;training_loss&quot;</span>, train_loss)</span></code></pre></div></li>
<li class="fragment"><img data-src="images/pl_tb.png" /></li>
</ul>
</section>
<section id="tensorboard-1" class="slide level2">
<h2>TensorBoard</h2>
<div class="sourceCode" id="cb23"><pre
class="sourceCode bash"><code class="sourceCode bash"><span id="cb23-1"><a href="#cb23-1" aria-hidden="true" tabindex="-1"></a><span class="bu">source</span> <span class="va">$HOME</span>/course/<span class="va">$USER</span>/sc_venv_template/activate.sh</span>
<span id="cb23-2"><a href="#cb23-2" aria-hidden="true" tabindex="-1"></a><span class="ex">tensorboard</span> <span class="at">--logdir</span><span class="op">=</span><span class="pp">[</span><span class="ss">PATH_TO_TENSOR_BOARD</span><span class="pp">]</span> </span></code></pre></div>
<p><img data-src="images/tb.png" width="750" /></p>
</section>
<section id="demo-3" class="slide level2">
<h2>DEMO</h2>
</section>
<section id="llview" class="slide level2">
<h2>Llview</h2>
<ul>
<li class="fragment"><a
href="https://go.fzj.de/llview-juwelsbooster">llview</a></li>
<li class="fragment">https://go.fzj.de/llview-juwelsbooster <img
data-src="images/llview.png" /></li>
</ul>
</section>
<section id="day-2-recap" class="slide level2">
<h2>DAY 2 RECAP</h2>
<ul>
<li class="fragment">Access using FS, Arrow, and H5 files</li>
<li class="fragment">Ran parallel code.</li>
<li class="fragment">Can submit single node, multi-gpu and multi-node
training.</li>
<li class="fragment">Use TensorBoard on the supercomputer.</li>
<li class="fragment">Usage of llview.</li>
</ul>
</section>
<section id="any-questions" class="slide level2">
<h2>ANY QUESTIONS??</h2>
<h4 id="feedback-is-more-than-welcome">Feedback is more than
welcome!</h4>
<h4 id="link-to-other-courses-at-jsc">Link to <a
href="https://go.fzj.de/intro-sc-ai-2023-other-courses">other courses at
JSC</a></h4>
</section>
<section class="slide level2">

</section>
    </div>
  </div>

  <script src="./dist/reveal.js"></script>

  <!-- reveal.js plugins -->
  <script src="./plugin/notes/notes.js"></script>
  <script src="./plugin/search/search.js"></script>
  <script src="./plugin/zoom/zoom.js"></script>

  <script>

      // Full list of configuration options available at:
      // https://revealjs.com/config/
      Reveal.initialize({
        // Display controls in the bottom right corner
        controls: true,

        // Help the user learn the controls by providing hints, for example by
        // bouncing the down arrow when they first encounter a vertical slide
        controlsTutorial: true,

        // Determines where controls appear, "edges" or "bottom-right"
        controlsLayout: 'bottom-right',

        // Visibility rule for backwards navigation arrows; "faded", "hidden"
        // or "visible"
        controlsBackArrows: 'faded',

        // Display a presentation progress bar
        progress: true,

        // Display the page number of the current slide
        slideNumber: false,

        // 'all', 'print', or 'speaker'
        showSlideNumber: 'all',

        // Add the current slide number to the URL hash so that reloading the
        // page/copying the URL will return you to the same slide
        hash: true,

        // Start with 1 for the hash rather than 0
        hashOneBasedIndex: false,

        // Flags if we should monitor the hash and change slides accordingly
        respondToHashChanges: true,

        // Push each slide change to the browser history
        history: false,

        // Enable keyboard shortcuts for navigation
        keyboard: true,

        // Enable the slide overview mode
        overview: true,

        // Disables the default reveal.js slide layout (scaling and centering)
        // so that you can use custom CSS layout
        disableLayout: false,

        // Vertical centering of slides
        center: true,

        // Enables touch navigation on devices with touch input
        touch: true,

        // Loop the presentation
        loop: false,

        // Change the presentation direction to be RTL
        rtl: false,

        // see https://revealjs.com/vertical-slides/#navigation-mode
        navigationMode: 'default',

        // Randomizes the order of slides each time the presentation loads
        shuffle: false,

        // Turns fragments on and off globally
        fragments: true,

        // Flags whether to include the current fragment in the URL,
        // so that reloading brings you to the same fragment position
        fragmentInURL: true,

        // Flags if the presentation is running in an embedded mode,
        // i.e. contained within a limited portion of the screen
        embedded: false,

        // Flags if we should show a help overlay when the questionmark
        // key is pressed
        help: true,

        // Flags if it should be possible to pause the presentation (blackout)
        pause: true,

        // Flags if speaker notes should be visible to all viewers
        showNotes: false,

        // Global override for autoplaying embedded media (null/true/false)
        autoPlayMedia: null,

        // Global override for preloading lazy-loaded iframes (null/true/false)
        preloadIframes: null,

        // Number of milliseconds between automatically proceeding to the
        // next slide, disabled when set to 0, this value can be overwritten
        // by using a data-autoslide attribute on your slides
        autoSlide: 0,

        // Stop auto-sliding after user input
        autoSlideStoppable: true,

        // Use this method for navigation when auto-sliding
        autoSlideMethod: null,

        // Specify the average time in seconds that you think you will spend
        // presenting each slide. This is used to show a pacing timer in the
        // speaker view
        defaultTiming: null,

        // Enable slide navigation via mouse wheel
        mouseWheel: false,

        // The display mode that will be used to show slides
        display: 'block',

        // Hide cursor if inactive
        hideInactiveCursor: true,

        // Time before the cursor is hidden (in ms)
        hideCursorTime: 5000,

        // Opens links in an iframe preview overlay
        previewLinks: false,

        // Transition style (none/fade/slide/convex/concave/zoom)
        transition: 'fade',

        // Transition speed (default/fast/slow)
        transitionSpeed: 'default',

        // Transition style for full page slide backgrounds
        // (none/fade/slide/convex/concave/zoom)
        backgroundTransition: 'fade',

        // Number of slides away from the current that are visible
        viewDistance: 3,

        // Number of slides away from the current that are visible on mobile
        // devices. It is advisable to set this to a lower number than
        // viewDistance in order to save resources.
        mobileViewDistance: 2,

        // reveal.js plugins
        plugins: [
          RevealNotes,
          RevealSearch,
          RevealZoom
        ]
      });
    </script>
    </body>
</html>
